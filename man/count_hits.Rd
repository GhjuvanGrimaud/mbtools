% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/counting.R
\name{count_hits}
\alias{count_hits}
\title{Count alignment hits to a reference database.}
\usage{
count_hits(alignment_files, reference, threads = 1, method = "em",
  maxit = 1000, cutoff = 0.01, counts = TRUE)
}
\arguments{
\item{alignment_files}{Paths to BAM files.}

\item{threads}{Number of parallel processes.}

\item{method}{The counting method. Can be either "naive" for assigning each
read to any transcript with the highest mapping score or "em" to resolve
multimapping with an expectation maximzation algorithm.}

\item{maxit}{Only for method="em". Maximum iterations of EM algorithm.}

\item{cutoff}{Only for method="em". Stop EM if maximum relative change in
transcript abundance is not at least this value. For instance a value of
0.01 (default) means that the EM algorithm is stopped if transcript
abundances change less than 1\% between iterations.}

\item{counts}{Whether to return counts. If FALSE returns transcripts per
million.}

\item{tags}{Additional tags to read in the BAM file.}
}
\value{
A data.table with transcript names, counts, effective transcript
 length and sample name.
}
\description{
This will correct for effective transcript lengths as done by almost any
good tool those days. So the returned counts are not correlated with
transcript lengths. By default an expectation maximization algorithm is
used to resolve multiple mappings of one read to many transcripts which
pretty much always happens in metagenomics data sets. The optimized
likelihodd function is very similar to the one in kallisto
(https://doi.org/10.1038/nbt.3519).
}
