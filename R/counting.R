# Helpers for counting transcript reads

#' Read alignments from a BAM file.
#'
#' @param path The file path to the BAM.
#' @param tags Additional tags to read from the BAM file.
#' @return The alignments in a GAlignments object.
#'
#' @export
#' @importFrom GenomicAlignments readGAlignments
#' @importFrom Rsamtools ScanBamParam
read_bam <- function(path, tags = character(0)) {
    bam <- readGAlignments(path, param=ScanBamParam(
        what=c("qname", "mapq"), tag=tags))
    return(bam)
}

#' @useDynLib mbtools, .registration = TRUE
#' @importFrom Rcpp sourceCpp
#' @importFrom stats quantile
count_alns <- function(alignments, txlengths, file, method = "em",
                       maxit = 1000, cutoff = 0.01, tpm = FALSE, ecs = FALSE) {
    aln <- as.data.table(alignments)
    aln[, seqnames := factor(as.character(seqnames))]
    if (is.null(txlengths)) {
        efflengths <- rep(1, aln[, length(levels(seqnames))])
    } else {
        efflengths <- effective_lengths(aln[, txlengths[levels(seqnames)]],
                                        aln[, width])
    }
    names(efflengths) <- aln[, txlengths[levels(seqnames)]]
    flog.info(paste("[%s] %d transcripts. Confidence interval for effective",
                    "lengths: [%.2f, %.2f]."),
              file, aln[, length(levels(seqnames))],
              quantile(efflengths, 0.025), quantile(efflengths, 0.975))
    if (nrow(aln) == 0) {
        return(data.table(transcript=character(), counts=integer(),
                          effective_length=integer()))
    }
    if (tpm) {
        libsize <- 1e6
    } else {
        libsize <-  aln[, uniqueN(qname)]  # return counts
    }
    equiv_classes <- NULL
    if (method == "naive") {
        aln <- aln[order(-mapq), .SD[1], by="qname"]
        counts <- aln[, .(counts = .N), by="seqnames"]
        names(counts)[1] <- "transcript"
        counts[, counts := counts / efflengths[transcript]]
        counts[, counts := counts / sum(counts) * libsize]
        counts[, effective_length := efflengths[transcript]]
    } else {
        aln[, seqnames := factor(seqnames)]
        aln[, qname := factor(qname)]
        txids <- aln[, as.integer(seqnames) - 1]
        txnames <- aln[, levels(seqnames)]
        rids <- aln[, as.integer(qname) - 1]
        em_result <- em_count(cbind(txids, rids), efflengths,
                              length(txnames), max(rids) + 1, maxit,
                              cutoff, cutoff)
        flog.info(paste("[%s] Used %d EM iterations on %d equivalence classes.",
                        "Last max. abs. change was %.2g."),
                  file, em_result$iterations, length(em_result$ecs),
                  max(em_result$change))
        equiv_classes <- em_result$ecs
        counts <- data.table(transcript = txnames,
                             counts = em_result$p,
                             effective_length = efflengths)
        if (tpm) {
            counts[, counts := em_result$p]
            print(libsize == max(rids) + 1)
            counts[counts < 1e-8, counts := 0]
        } else {
            counts[counts < cutoff, counts := 0]
        }
        counts <- counts[counts > 0]
    }
    if (ecs) {
        list(counts = counts, ecs = equiv_classes)
    } else {
        return(counts)
    }
    return(counts)
}

#' Build a configuration for the transcript counting workflow.
#'
#' This can be saved and passed on to others to ensure reproducibility.
#'
#' @param ... Any arguments are used to update the default configuration. See
#'  the example below. Optional.
#' @return A list with the parameters used in the transcript counting
#'  workflow.
#' @export
#' @examples
#'  config <- config_count(reference = "refs/mouse.fna.gz")
config_count <- function(...) {
    config <- list(
        reference = NA,
        threads = 1,
        method = "em",
        maxit = 1000,
        cutoff = 0.01,
        tpm = FALSE
    )
    args <- list(...)
    for (arg in names(args)) {
        config[[arg]] <- args[[arg]]
    }
    return(config)
}

#' Count alignment hits to a reference database.
#'
#' This will correct for effective transcript lengths as done by almost any
#' good tool those days. So the returned counts are not correlated with
#' transcript lengths. By default an expectation maximization algorithm is
#' used to resolve multiple mappings of one read to many transcripts which
#' pretty much always happens in metagenomics data sets. The optimized
#' likelihodd function is very similar to the one in kallisto
#' (https://doi.org/10.1038/nbt.3519).
#'
#' @param object An experiment data table as returned by any alignment method
#'  like \code{\link{align_short_reads}} or \code{\link{align_long_reads}} .
#' @param config A configuration as generated by \code{\link{config_count}}.
#' @return A list containing the used alignments and the transcript counts in
#'  `counts`.
#'
#' @export
#' @importFrom data.table tstrsplit
count_transcripts <- function(object, config) {
    if (is.na(config$reference)) {
        flog.info(paste("No reference given so assuming constant length",
                        "transcripts. Starting counting..."))
        txlengths <- NULL
    } else {
        flog.info("Getting transcript lengths from %s...", config$reference)
        fasta_index <- fasta.index(config$reference)[, c("desc", "seqlength")]
        txlengths <- fasta_index$seqlength
        names(txlengths) <- gsub("\\s.+", "", fasta_index$desc)
        flog.info("Normalized IDs. Starting counting...")
    }
    counts <- mclapply(object$alignments$alignment, function(file) {
        bam <- read_bam(file)
        flog.info("[%s] Read %d alignments.", file, length(bam))
        cn <- count_alns(bam, txlengths, file = file)
        cn[, "sample" := strsplit(basename(file), ".bam")[[1]][1]]
        return(cn)
    }, mc.cores = config$threads)

    artifact <- list(
        alignments = object$alignments,
        counts = rbindlist(counts),
        steps = c(object[["steps"]], "count_transcripts")
    )
    return(artifact)
}
